{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75255708",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sign                              filename\n",
      "0     0  200d8766-4240-44d1-a2da-65dc4ee7973a\n",
      "1     0  87174854-b7b6-4cb2-8183-4ca2bbd26b9d\n",
      "2     0  c089638e-b683-436a-a3a3-3e5be972c4f6\n",
      "3     1  8790e76c-f485-49a6-abaf-3147436ca085\n",
      "4     0  c06b01db-8934-4c72-b568-508a32c4b170\n",
      "[0 0 0 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.head(5))\n",
    "\n",
    "y_train = data['sign'].to_numpy()\n",
    "y_train = np.hstack((y_train, y_train))\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "015918b5",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sign                              filename\n",
      "0     0  200d8766-4240-44d1-a2da-65dc4ee7973a\n",
      "1     0  87174854-b7b6-4cb2-8183-4ca2bbd26b9d\n",
      "2     0  c089638e-b683-436a-a3a3-3e5be972c4f6\n",
      "3     1  8790e76c-f485-49a6-abaf-3147436ca085\n",
      "4     0  c06b01db-8934-4c72-b568-508a32c4b170\n",
      "(932400, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndirectory = os.path.join(curr_path, \"avia-train30-random_alignment/avia-train\")\\narr_image_list2 = []\\nfor row in data.values:\\n    abspath = os.path.join(directory, row[1]+ \\'.png\\')\\n    image = cv2.imread(abspath, 0)\\n    arr_image = np.asarray(image)\\n    arr_image_list2.append(arr_image)\\narr_image_list2 = np.vstack(arr_image_list2)\\nprint(arr_image_list2.shape)\\n\\ndirectory = os.path.join(curr_path, \"avia-train30-random2_alignment/avia-train\")\\narr_image_list3 = []\\nfor row in data.values:\\n    abspath = os.path.join(directory, row[1]+ \\'.png\\')\\n    image = cv2.imread(abspath, 0)\\n    arr_image = np.asarray(image)\\n    arr_image_list3.append(arr_image)\\narr_image_list3 = np.vstack(arr_image_list3)\\nprint(arr_image_list3.shape)\\n\\n\\ndirectory = os.path.join(curr_path, \"avia-train30-random_alignment3/avia-train\")\\narr_image_list4 = []\\nfor row in data.values:\\n    abspath = os.path.join(directory, row[1]+ \\'.png\\')\\n    image = cv2.imread(abspath, 0)\\n    arr_image = np.asarray(image)\\n    arr_image_list4.append(arr_image)\\narr_image_list4 = np.vstack(arr_image_list4)\\nprint(arr_image_list4.shape)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "from pathlib import Path\n",
    "curr_path = os.getcwd()\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.head(5))\n",
    "\n",
    "directory = os.path.join(curr_path, \"avia-train30_alignment/avia-train\")\n",
    "arr_image_list1 = []\n",
    "for row in data.values:\n",
    "    abspath = os.path.join(directory, row[1]+ '.png')\n",
    "    image = cv2.imread(abspath, 0)\n",
    "    arr_image = np.asarray(image)\n",
    "    arr_image_list1.append(arr_image)\n",
    "arr_image_list1 = np.vstack(arr_image_list1)\n",
    "print(arr_image_list1.shape)\n",
    "\"\"\"\n",
    "directory = os.path.join(curr_path, \"avia-train30-random_alignment/avia-train\")\n",
    "arr_image_list2 = []\n",
    "for row in data.values:\n",
    "    abspath = os.path.join(directory, row[1]+ '.png')\n",
    "    image = cv2.imread(abspath, 0)\n",
    "    arr_image = np.asarray(image)\n",
    "    arr_image_list2.append(arr_image)\n",
    "arr_image_list2 = np.vstack(arr_image_list2)\n",
    "print(arr_image_list2.shape)\n",
    "\n",
    "directory = os.path.join(curr_path, \"avia-train30-random2_alignment/avia-train\")\n",
    "arr_image_list3 = []\n",
    "for row in data.values:\n",
    "    abspath = os.path.join(directory, row[1]+ '.png')\n",
    "    image = cv2.imread(abspath, 0)\n",
    "    arr_image = np.asarray(image)\n",
    "    arr_image_list3.append(arr_image)\n",
    "arr_image_list3 = np.vstack(arr_image_list3)\n",
    "print(arr_image_list3.shape)\n",
    "\n",
    "\n",
    "directory = os.path.join(curr_path, \"avia-train30-random_alignment3/avia-train\")\n",
    "arr_image_list4 = []\n",
    "for row in data.values:\n",
    "    abspath = os.path.join(directory, row[1]+ '.png')\n",
    "    image = cv2.imread(abspath, 0)\n",
    "    arr_image = np.asarray(image)\n",
    "    arr_image_list4.append(arr_image)\n",
    "arr_image_list4 = np.vstack(arr_image_list4)\n",
    "print(arr_image_list4.shape)\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b0a0fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(932400, 30)\n"
     ]
    }
   ],
   "source": [
    "#arr_image_list = np.vstack((arr_image_list1, arr_image_list2, arr_image_list3))\n",
    "\n",
    "print(arr_image_list1.shape)\n",
    "np.savetxt(\"np_image_train_5.csv\", arr_image_list1, delimiter=\";\", fmt = '%3.0d')\n",
    "#X = np.array([part[0] for part in reviews_with_len])\n",
    "#Y = np.array([part[1] for part in reviews_with_len])\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b321e56f",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               filename\n",
      "0  68f33844-472b-4111-b600-f90d544833c7\n",
      "1  7d93a21d-1f16-49ce-8fcc-edf12c40f549\n",
      "2  4a820650-7acd-489a-ad14-9d7ad8c73b6b\n",
      "3  819b216b-2b6c-4539-a722-70648c0706c6\n",
      "4  45f7c47d-03cc-40cd-acc5-b8c1c57872fa\n",
      "(30000, 30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "from pathlib import Path\n",
    "curr_path = os.getcwd()\n",
    "\n",
    "data1 = pd.read_csv('test.csv')\n",
    "print(data1.head(5))\n",
    "directory = os.path.join(curr_path, \"avia-test30_alignment/avia-test\")\n",
    "arr_image_list = []\n",
    "for row in data1.values:\n",
    "    abspath = os.path.join(directory, row[0]+ '.png')\n",
    "    image = cv2.imread(abspath, 0)\n",
    "    arr_image = np.asarray(image)\n",
    "    arr_image_list.append(arr_image)\n",
    "arr_image_list = np.vstack(arr_image_list)\n",
    "\n",
    "print(arr_image_list.shape)\n",
    "np.savetxt(\"np_image_test.csv\", arr_image_list, delimiter=\";\", fmt = '%3.0d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1974b40",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eafd3321",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(932400, 30)\n",
      "(30000, 30)\n",
      "(31080, 30, 30, 1)\n",
      "(1000, 30, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.loadtxt('np_image_train_5.csv', delimiter=\";\")\n",
    "#data_train = data_train.sample(frac = 1).reset_index(drop = True)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_test = np.loadtxt('np_image_test.csv', delimiter=\";\")\n",
    "print(x_test.shape)\n",
    "\n",
    "x_train = x_train.reshape(31080,30,30,1)\n",
    "x_test = x_test.reshape(1000,30,30,1)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2dd471a",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sign                              filename\n",
      "0     0  200d8766-4240-44d1-a2da-65dc4ee7973a\n",
      "1     0  87174854-b7b6-4cb2-8183-4ca2bbd26b9d\n",
      "2     0  c089638e-b683-436a-a3a3-3e5be972c4f6\n",
      "3     1  8790e76c-f485-49a6-abaf-3147436ca085\n",
      "4     0  c06b01db-8934-4c72-b568-508a32c4b170\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#Xtrain, Xval, Ytrain, Yval = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "import pandas as pd\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.head(5))\n",
    "y_train = data['sign'].to_numpy()\n",
    "#y_train = np.hstack((y_train, y_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef70a72e",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from keras import backend as K \n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43e9104a",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 21, 21, 32)        3232      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        131136    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 9, 9, 128)         295040    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 5, 5, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,322,913\n",
      "Trainable params: 1,322,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = tf.Session(config=config)\n",
    "\n",
    "optimizer = Adam(lr=0.00001)\n",
    "\n",
    "# создание модели\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (10,10), activation='relu', input_shape=(30,30,1)))\n",
    "model.add(Conv2D(64, (8,8), activation='relu'))\n",
    "model.add(Conv2D(128, (6,6), activation='relu'))\n",
    "model.add(Conv2D(256, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, 'relu'))\n",
    "model.add(Dense(32, 'relu'))\n",
    "model.add(Dense(1, 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce4adb9",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "110/110 [==============================] - 7s 30ms/step - loss: 1.3441 - accuracy: 0.6380 - precision: 0.3527 - recall: 0.3921 - f1: 0.3415 - val_loss: 0.3917 - val_accuracy: 0.8047 - val_precision: 0.7296 - val_recall: 0.3912 - val_f1: 0.5064\n",
      "Epoch 2/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.4506 - accuracy: 0.7845 - precision: 0.5983 - recall: 0.5200 - f1: 0.5533 - val_loss: 0.3139 - val_accuracy: 0.8629 - val_precision: 0.7409 - val_recall: 0.7230 - val_f1: 0.7307\n",
      "Epoch 3/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.3378 - accuracy: 0.8460 - precision: 0.7128 - recall: 0.6576 - f1: 0.6815 - val_loss: 0.2561 - val_accuracy: 0.8977 - val_precision: 0.7901 - val_recall: 0.8089 - val_f1: 0.7985\n",
      "Epoch 4/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.2755 - accuracy: 0.8821 - precision: 0.7831 - recall: 0.7591 - f1: 0.7682 - val_loss: 0.2160 - val_accuracy: 0.9093 - val_precision: 0.8406 - val_recall: 0.7993 - val_f1: 0.8183\n",
      "Epoch 5/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.2327 - accuracy: 0.9046 - precision: 0.8282 - recall: 0.7909 - f1: 0.8072 - val_loss: 0.1903 - val_accuracy: 0.9237 - val_precision: 0.8629 - val_recall: 0.8232 - val_f1: 0.8419\n",
      "Epoch 6/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.2021 - accuracy: 0.9214 - precision: 0.8549 - recall: 0.8330 - f1: 0.8424 - val_loss: 0.1656 - val_accuracy: 0.9286 - val_precision: 0.8718 - val_recall: 0.8341 - val_f1: 0.8514\n",
      "Epoch 7/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1829 - accuracy: 0.9272 - precision: 0.8689 - recall: 0.8410 - f1: 0.8534 - val_loss: 0.1484 - val_accuracy: 0.9408 - val_precision: 0.8822 - val_recall: 0.8797 - val_f1: 0.8802\n",
      "Epoch 8/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1652 - accuracy: 0.9374 - precision: 0.8882 - recall: 0.8624 - f1: 0.8739 - val_loss: 0.1412 - val_accuracy: 0.9427 - val_precision: 0.9050 - val_recall: 0.8513 - val_f1: 0.8763\n",
      "Epoch 9/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1508 - accuracy: 0.9414 - precision: 0.8977 - recall: 0.8700 - f1: 0.8820 - val_loss: 0.1375 - val_accuracy: 0.9434 - val_precision: 0.9160 - val_recall: 0.8415 - val_f1: 0.8769\n",
      "Epoch 10/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1473 - accuracy: 0.9450 - precision: 0.9050 - recall: 0.8786 - f1: 0.8899 - val_loss: 0.1279 - val_accuracy: 0.9488 - val_precision: 0.8756 - val_recall: 0.9289 - val_f1: 0.9009\n",
      "Epoch 11/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1370 - accuracy: 0.9463 - precision: 0.8992 - recall: 0.8892 - f1: 0.8929 - val_loss: 0.1194 - val_accuracy: 0.9540 - val_precision: 0.8992 - val_recall: 0.9185 - val_f1: 0.9083\n",
      "Epoch 12/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1285 - accuracy: 0.9518 - precision: 0.9139 - recall: 0.8953 - f1: 0.9034 - val_loss: 0.1131 - val_accuracy: 0.9553 - val_precision: 0.9068 - val_recall: 0.9152 - val_f1: 0.9102\n",
      "Epoch 13/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1286 - accuracy: 0.9515 - precision: 0.9091 - recall: 0.9005 - f1: 0.9035 - val_loss: 0.1114 - val_accuracy: 0.9559 - val_precision: 0.9122 - val_recall: 0.9027 - val_f1: 0.9070\n",
      "Epoch 14/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1196 - accuracy: 0.9572 - precision: 0.9255 - recall: 0.9046 - f1: 0.9140 - val_loss: 0.1058 - val_accuracy: 0.9588 - val_precision: 0.9218 - val_recall: 0.9103 - val_f1: 0.9153\n",
      "Epoch 15/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.1098 - accuracy: 0.9599 - precision: 0.9279 - recall: 0.9134 - f1: 0.9200 - val_loss: 0.1177 - val_accuracy: 0.9543 - val_precision: 0.8730 - val_recall: 0.9545 - val_f1: 0.9113\n",
      "Epoch 16/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1112 - accuracy: 0.9594 - precision: 0.9217 - recall: 0.9168 - f1: 0.9186 - val_loss: 0.1034 - val_accuracy: 0.9617 - val_precision: 0.9033 - val_recall: 0.9435 - val_f1: 0.9226\n",
      "Epoch 17/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.1003 - accuracy: 0.9630 - precision: 0.9325 - recall: 0.9243 - f1: 0.9273 - val_loss: 0.0971 - val_accuracy: 0.9627 - val_precision: 0.9246 - val_recall: 0.9210 - val_f1: 0.9224\n",
      "Epoch 18/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.1031 - accuracy: 0.9628 - precision: 0.9357 - recall: 0.9164 - f1: 0.9253 - val_loss: 0.1085 - val_accuracy: 0.9585 - val_precision: 0.8774 - val_recall: 0.9665 - val_f1: 0.9193\n",
      "Epoch 19/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0976 - accuracy: 0.9649 - precision: 0.9346 - recall: 0.9263 - f1: 0.9295 - val_loss: 0.1038 - val_accuracy: 0.9601 - val_precision: 0.8864 - val_recall: 0.9608 - val_f1: 0.9215\n",
      "Epoch 20/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0941 - accuracy: 0.9642 - precision: 0.9291 - recall: 0.9292 - f1: 0.9284 - val_loss: 0.1000 - val_accuracy: 0.9617 - val_precision: 0.8885 - val_recall: 0.9643 - val_f1: 0.9244\n",
      "Epoch 21/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0884 - accuracy: 0.9668 - precision: 0.9349 - recall: 0.9342 - f1: 0.9338 - val_loss: 0.0926 - val_accuracy: 0.9669 - val_precision: 0.9116 - val_recall: 0.9531 - val_f1: 0.9314\n",
      "Epoch 22/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0900 - accuracy: 0.9675 - precision: 0.9370 - recall: 0.9346 - f1: 0.9349 - val_loss: 0.0987 - val_accuracy: 0.9630 - val_precision: 0.8913 - val_recall: 0.9655 - val_f1: 0.9265\n",
      "Epoch 23/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0855 - accuracy: 0.9687 - precision: 0.9399 - recall: 0.9384 - f1: 0.9386 - val_loss: 0.0965 - val_accuracy: 0.9653 - val_precision: 0.9008 - val_recall: 0.9623 - val_f1: 0.9300\n",
      "Epoch 24/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0817 - accuracy: 0.9709 - precision: 0.9404 - recall: 0.9432 - f1: 0.9414 - val_loss: 0.0900 - val_accuracy: 0.9678 - val_precision: 0.9073 - val_recall: 0.9629 - val_f1: 0.9339\n",
      "Epoch 25/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0750 - accuracy: 0.9728 - precision: 0.9470 - recall: 0.9467 - f1: 0.9463 - val_loss: 0.0874 - val_accuracy: 0.9691 - val_precision: 0.9115 - val_recall: 0.9611 - val_f1: 0.9352\n",
      "Epoch 26/500\n",
      "110/110 [==============================] - 3s 25ms/step - loss: 0.0743 - accuracy: 0.9742 - precision: 0.9509 - recall: 0.9462 - f1: 0.9482 - val_loss: 0.0808 - val_accuracy: 0.9698 - val_precision: 0.9403 - val_recall: 0.9379 - val_f1: 0.9379\n",
      "Epoch 27/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0752 - accuracy: 0.9735 - precision: 0.9497 - recall: 0.9462 - f1: 0.9474 - val_loss: 0.0858 - val_accuracy: 0.9691 - val_precision: 0.9193 - val_recall: 0.9594 - val_f1: 0.9386\n",
      "Epoch 28/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0784 - accuracy: 0.9707 - precision: 0.9488 - recall: 0.9350 - f1: 0.9408 - val_loss: 0.0816 - val_accuracy: 0.9717 - val_precision: 0.9477 - val_recall: 0.9359 - val_f1: 0.9406\n",
      "Epoch 29/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0684 - accuracy: 0.9770 - precision: 0.9564 - recall: 0.9529 - f1: 0.9541 - val_loss: 0.0805 - val_accuracy: 0.9694 - val_precision: 0.9252 - val_recall: 0.9458 - val_f1: 0.9347\n",
      "Epoch 30/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0639 - accuracy: 0.9769 - precision: 0.9586 - recall: 0.9506 - f1: 0.9541 - val_loss: 0.0806 - val_accuracy: 0.9723 - val_precision: 0.9219 - val_recall: 0.9534 - val_f1: 0.9369\n",
      "Epoch 31/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0629 - accuracy: 0.9777 - precision: 0.9585 - recall: 0.9525 - f1: 0.9551 - val_loss: 0.0759 - val_accuracy: 0.9736 - val_precision: 0.9326 - val_recall: 0.9525 - val_f1: 0.9418\n",
      "Epoch 32/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0595 - accuracy: 0.9793 - precision: 0.9609 - recall: 0.9557 - f1: 0.9580 - val_loss: 0.0917 - val_accuracy: 0.9685 - val_precision: 0.9006 - val_recall: 0.9739 - val_f1: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0594 - accuracy: 0.9790 - precision: 0.9566 - recall: 0.9610 - f1: 0.9582 - val_loss: 0.0844 - val_accuracy: 0.9694 - val_precision: 0.9112 - val_recall: 0.9635 - val_f1: 0.9357\n",
      "Epoch 34/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0624 - accuracy: 0.9768 - precision: 0.9537 - recall: 0.9542 - f1: 0.9535 - val_loss: 0.0742 - val_accuracy: 0.9755 - val_precision: 0.9542 - val_recall: 0.9365 - val_f1: 0.9448\n",
      "Epoch 35/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0528 - accuracy: 0.9815 - precision: 0.9669 - recall: 0.9591 - f1: 0.9626 - val_loss: 0.0781 - val_accuracy: 0.9710 - val_precision: 0.9265 - val_recall: 0.9584 - val_f1: 0.9418\n",
      "Epoch 36/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0556 - accuracy: 0.9803 - precision: 0.9643 - recall: 0.9570 - f1: 0.9602 - val_loss: 0.0726 - val_accuracy: 0.9733 - val_precision: 0.9304 - val_recall: 0.9538 - val_f1: 0.9414\n",
      "Epoch 37/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0538 - accuracy: 0.9799 - precision: 0.9643 - recall: 0.9569 - f1: 0.9598 - val_loss: 0.0756 - val_accuracy: 0.9717 - val_precision: 0.9429 - val_recall: 0.9493 - val_f1: 0.9455\n",
      "Epoch 38/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0495 - accuracy: 0.9824 - precision: 0.9661 - recall: 0.9643 - f1: 0.9649 - val_loss: 0.0747 - val_accuracy: 0.9739 - val_precision: 0.9509 - val_recall: 0.9320 - val_f1: 0.9409\n",
      "Epoch 39/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0478 - accuracy: 0.9842 - precision: 0.9717 - recall: 0.9653 - f1: 0.9681 - val_loss: 0.0750 - val_accuracy: 0.9733 - val_precision: 0.9517 - val_recall: 0.9301 - val_f1: 0.9401\n",
      "Epoch 40/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0479 - accuracy: 0.9834 - precision: 0.9715 - recall: 0.9630 - f1: 0.9668 - val_loss: 0.0734 - val_accuracy: 0.9727 - val_precision: 0.9364 - val_recall: 0.9448 - val_f1: 0.9401\n",
      "Epoch 41/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0460 - accuracy: 0.9841 - precision: 0.9692 - recall: 0.9674 - f1: 0.9681 - val_loss: 0.0793 - val_accuracy: 0.9710 - val_precision: 0.9655 - val_recall: 0.9151 - val_f1: 0.9385\n",
      "Epoch 42/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0426 - accuracy: 0.9853 - precision: 0.9730 - recall: 0.9696 - f1: 0.9709 - val_loss: 0.0755 - val_accuracy: 0.9733 - val_precision: 0.9705 - val_recall: 0.9179 - val_f1: 0.9426\n",
      "Epoch 43/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0440 - accuracy: 0.9848 - precision: 0.9760 - recall: 0.9638 - f1: 0.9696 - val_loss: 0.0866 - val_accuracy: 0.9688 - val_precision: 0.9631 - val_recall: 0.8936 - val_f1: 0.9263\n",
      "Epoch 44/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0454 - accuracy: 0.9844 - precision: 0.9746 - recall: 0.9632 - f1: 0.9684 - val_loss: 0.0755 - val_accuracy: 0.9749 - val_precision: 0.9387 - val_recall: 0.9503 - val_f1: 0.9439\n",
      "Epoch 45/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0390 - accuracy: 0.9864 - precision: 0.9754 - recall: 0.9701 - f1: 0.9726 - val_loss: 0.0750 - val_accuracy: 0.9736 - val_precision: 0.9248 - val_recall: 0.9627 - val_f1: 0.9427\n",
      "Epoch 46/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0394 - accuracy: 0.9853 - precision: 0.9709 - recall: 0.9719 - f1: 0.9711 - val_loss: 0.0730 - val_accuracy: 0.9746 - val_precision: 0.9448 - val_recall: 0.9421 - val_f1: 0.9429\n",
      "Epoch 47/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0401 - accuracy: 0.9869 - precision: 0.9774 - recall: 0.9712 - f1: 0.9740 - val_loss: 0.0787 - val_accuracy: 0.9730 - val_precision: 0.9717 - val_recall: 0.9157 - val_f1: 0.9421\n",
      "Epoch 48/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0398 - accuracy: 0.9862 - precision: 0.9769 - recall: 0.9684 - f1: 0.9724 - val_loss: 0.0793 - val_accuracy: 0.9752 - val_precision: 0.9229 - val_recall: 0.9718 - val_f1: 0.9459\n",
      "Epoch 49/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0348 - accuracy: 0.9881 - precision: 0.9757 - recall: 0.9780 - f1: 0.9766 - val_loss: 0.0699 - val_accuracy: 0.9768 - val_precision: 0.9556 - val_recall: 0.9385 - val_f1: 0.9465\n",
      "Epoch 50/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0313 - accuracy: 0.9891 - precision: 0.9801 - recall: 0.9773 - f1: 0.9785 - val_loss: 0.0725 - val_accuracy: 0.9749 - val_precision: 0.9410 - val_recall: 0.9483 - val_f1: 0.9441\n",
      "Epoch 51/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0332 - accuracy: 0.9885 - precision: 0.9803 - recall: 0.9745 - f1: 0.9772 - val_loss: 0.0738 - val_accuracy: 0.9765 - val_precision: 0.9355 - val_recall: 0.9611 - val_f1: 0.9475\n",
      "Epoch 52/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0281 - accuracy: 0.9910 - precision: 0.9838 - recall: 0.9809 - f1: 0.9822 - val_loss: 0.0668 - val_accuracy: 0.9791 - val_precision: 0.9674 - val_recall: 0.9433 - val_f1: 0.954280 - accuracy: 0.9911 - precision: 0.9839 - recall: 0.9809 - f1: 0.98\n",
      "Epoch 53/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0312 - accuracy: 0.9897 - precision: 0.9810 - recall: 0.9766 - f1: 0.9786 - val_loss: 0.0729 - val_accuracy: 0.9762 - val_precision: 0.9551 - val_recall: 0.9361 - val_f1: 0.9450\n",
      "Epoch 54/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0292 - accuracy: 0.9898 - precision: 0.9825 - recall: 0.9771 - f1: 0.9796 - val_loss: 0.0722 - val_accuracy: 0.9759 - val_precision: 0.9562 - val_recall: 0.9338 - val_f1: 0.9445\n",
      "Epoch 55/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0336 - accuracy: 0.9887 - precision: 0.9831 - recall: 0.9719 - f1: 0.9772 - val_loss: 0.0707 - val_accuracy: 0.9759 - val_precision: 0.9452 - val_recall: 0.9472 - val_f1: 0.9457\n",
      "Epoch 56/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0286 - accuracy: 0.9911 - precision: 0.9827 - recall: 0.9825 - f1: 0.9824 - val_loss: 0.0730 - val_accuracy: 0.9759 - val_precision: 0.9273 - val_recall: 0.9615 - val_f1: 0.9438\n",
      "Epoch 57/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0279 - accuracy: 0.9903 - precision: 0.9826 - recall: 0.9789 - f1: 0.9806 - val_loss: 0.0694 - val_accuracy: 0.9778 - val_precision: 0.9377 - val_recall: 0.9633 - val_f1: 0.9498\n",
      "Epoch 58/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0264 - accuracy: 0.9913 - precision: 0.9840 - recall: 0.9817 - f1: 0.9827 - val_loss: 0.0744 - val_accuracy: 0.9752 - val_precision: 0.9670 - val_recall: 0.9280 - val_f1: 0.9462\n",
      "Epoch 59/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0254 - accuracy: 0.9921 - precision: 0.9866 - recall: 0.9823 - f1: 0.9843 - val_loss: 0.0707 - val_accuracy: 0.9765 - val_precision: 0.9341 - val_recall: 0.9624 - val_f1: 0.9475\n",
      "Epoch 60/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0296 - accuracy: 0.9902 - precision: 0.9819 - recall: 0.9795 - f1: 0.9804 - val_loss: 0.0694 - val_accuracy: 0.9768 - val_precision: 0.9627 - val_recall: 0.9386 - val_f1: 0.9495\n",
      "Epoch 61/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0248 - accuracy: 0.9917 - precision: 0.9852 - recall: 0.9829 - f1: 0.9839 - val_loss: 0.0715 - val_accuracy: 0.9791 - val_precision: 0.9530 - val_recall: 0.9510 - val_f1: 0.9515\n",
      "Epoch 62/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0247 - accuracy: 0.9921 - precision: 0.9847 - recall: 0.9837 - f1: 0.9840 - val_loss: 0.0710 - val_accuracy: 0.9788 - val_precision: 0.9576 - val_recall: 0.9427 - val_f1: 0.9497\n",
      "Epoch 63/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0240 - accuracy: 0.9920 - precision: 0.9858 - recall: 0.9828 - f1: 0.9840 - val_loss: 0.0746 - val_accuracy: 0.9752 - val_precision: 0.9632 - val_recall: 0.9326 - val_f1: 0.9466\n",
      "Epoch 64/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0194 - accuracy: 0.9934 - precision: 0.9880 - recall: 0.9859 - f1: 0.9868 - val_loss: 0.0711 - val_accuracy: 0.9788 - val_precision: 0.9641 - val_recall: 0.9446 - val_f1: 0.9533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0213 - accuracy: 0.9929 - precision: 0.9873 - recall: 0.9838 - f1: 0.9854 - val_loss: 0.0773 - val_accuracy: 0.9765 - val_precision: 0.9590 - val_recall: 0.9406 - val_f1: 0.9487\n",
      "Epoch 66/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0203 - accuracy: 0.9934 - precision: 0.9874 - recall: 0.9869 - f1: 0.9870 - val_loss: 0.0744 - val_accuracy: 0.9801 - val_precision: 0.9444 - val_recall: 0.9640 - val_f1: 0.9536\n",
      "Epoch 67/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0204 - accuracy: 0.9930 - precision: 0.9875 - recall: 0.9852 - f1: 0.9862 - val_loss: 0.0702 - val_accuracy: 0.9778 - val_precision: 0.9484 - val_recall: 0.9500 - val_f1: 0.9487\n",
      "Epoch 68/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0192 - accuracy: 0.9948 - precision: 0.9929 - recall: 0.9867 - f1: 0.9897 - val_loss: 0.0731 - val_accuracy: 0.9797 - val_precision: 0.9506 - val_recall: 0.9551 - val_f1: 0.9525\n",
      "Epoch 69/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0181 - accuracy: 0.9944 - precision: 0.9906 - recall: 0.9876 - f1: 0.9890 - val_loss: 0.0727 - val_accuracy: 0.9775 - val_precision: 0.9734 - val_recall: 0.9301 - val_f1: 0.9504\n",
      "Epoch 70/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0172 - accuracy: 0.9941 - precision: 0.9896 - recall: 0.9870 - f1: 0.9882 - val_loss: 0.0728 - val_accuracy: 0.9813 - val_precision: 0.9646 - val_recall: 0.9541 - val_f1: 0.9584\n",
      "Epoch 71/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0159 - accuracy: 0.9954 - precision: 0.9920 - recall: 0.9902 - f1: 0.9911 - val_loss: 0.0779 - val_accuracy: 0.9801 - val_precision: 0.9648 - val_recall: 0.9494 - val_f1: 0.9560\n",
      "Epoch 72/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0163 - accuracy: 0.9950 - precision: 0.9912 - recall: 0.9891 - f1: 0.9901 - val_loss: 0.0718 - val_accuracy: 0.9797 - val_precision: 0.9712 - val_recall: 0.9408 - val_f1: 0.9549\n",
      "Epoch 73/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0163 - accuracy: 0.9945 - precision: 0.9902 - recall: 0.9884 - f1: 0.9892 - val_loss: 0.0728 - val_accuracy: 0.9804 - val_precision: 0.9572 - val_recall: 0.9502 - val_f1: 0.9533\n",
      "Epoch 74/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0154 - accuracy: 0.9952 - precision: 0.9919 - recall: 0.9894 - f1: 0.9906 - val_loss: 0.0765 - val_accuracy: 0.9781 - val_precision: 0.9730 - val_recall: 0.9330 - val_f1: 0.9518\n",
      "Epoch 75/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0136 - accuracy: 0.9956 - precision: 0.9920 - recall: 0.9903 - f1: 0.9911 - val_loss: 0.0838 - val_accuracy: 0.9775 - val_precision: 0.9745 - val_recall: 0.9293 - val_f1: 0.9505\n",
      "Epoch 76/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0174 - accuracy: 0.9937 - precision: 0.9885 - recall: 0.9869 - f1: 0.9875 - val_loss: 0.0819 - val_accuracy: 0.9778 - val_precision: 0.9447 - val_recall: 0.9640 - val_f1: 0.9529\n",
      "Epoch 77/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0136 - accuracy: 0.9952 - precision: 0.9918 - recall: 0.9892 - f1: 0.9904 - val_loss: 0.0754 - val_accuracy: 0.9791 - val_precision: 0.9612 - val_recall: 0.9496 - val_f1: 0.9543\n",
      "Epoch 78/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0140 - accuracy: 0.9960 - precision: 0.9924 - recall: 0.9914 - f1: 0.9918 - val_loss: 0.0790 - val_accuracy: 0.9788 - val_precision: 0.9434 - val_recall: 0.9606 - val_f1: 0.9514\n",
      "Epoch 79/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0121 - accuracy: 0.9964 - precision: 0.9941 - recall: 0.9916 - f1: 0.9928 - val_loss: 0.0782 - val_accuracy: 0.9772 - val_precision: 0.9710 - val_recall: 0.9320 - val_f1: 0.9503\n",
      "Epoch 80/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0136 - accuracy: 0.9962 - precision: 0.9928 - recall: 0.9918 - f1: 0.9922 - val_loss: 0.0775 - val_accuracy: 0.9778 - val_precision: 0.9360 - val_recall: 0.9663 - val_f1: 0.9503\n",
      "Epoch 81/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0133 - accuracy: 0.9958 - precision: 0.9918 - recall: 0.9916 - f1: 0.9916 - val_loss: 0.0757 - val_accuracy: 0.9778 - val_precision: 0.9608 - val_recall: 0.9374 - val_f1: 0.9485\n",
      "Epoch 82/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0122 - accuracy: 0.9960 - precision: 0.9926 - recall: 0.9913 - f1: 0.9919 - val_loss: 0.0763 - val_accuracy: 0.9801 - val_precision: 0.9487 - val_recall: 0.9584 - val_f1: 0.9532\n",
      "Epoch 83/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0116 - accuracy: 0.9963 - precision: 0.9942 - recall: 0.9914 - f1: 0.9928 - val_loss: 0.0779 - val_accuracy: 0.9810 - val_precision: 0.9756 - val_recall: 0.9416 - val_f1: 0.9574\n",
      "Epoch 84/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0094 - accuracy: 0.9972 - precision: 0.9947 - recall: 0.9944 - f1: 0.9945 - val_loss: 0.0759 - val_accuracy: 0.9797 - val_precision: 0.9590 - val_recall: 0.9546 - val_f1: 0.9557\n",
      "Epoch 85/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0108 - accuracy: 0.9965 - precision: 0.9945 - recall: 0.9912 - f1: 0.9928 - val_loss: 0.0783 - val_accuracy: 0.9807 - val_precision: 0.9439 - val_recall: 0.9601 - val_f1: 0.9518\n",
      "Epoch 86/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0107 - accuracy: 0.9967 - precision: 0.9943 - recall: 0.9919 - f1: 0.9931 - val_loss: 0.0797 - val_accuracy: 0.9807 - val_precision: 0.9627 - val_recall: 0.9544 - val_f1: 0.9575\n",
      "Epoch 87/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0111 - accuracy: 0.9960 - precision: 0.9927 - recall: 0.9913 - f1: 0.9919 - val_loss: 0.0767 - val_accuracy: 0.9797 - val_precision: 0.9642 - val_recall: 0.9498 - val_f1: 0.9559\n",
      "Epoch 88/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0110 - accuracy: 0.9964 - precision: 0.9940 - recall: 0.9920 - f1: 0.9929 - val_loss: 0.0875 - val_accuracy: 0.9775 - val_precision: 0.9767 - val_recall: 0.9270 - val_f1: 0.9503\n",
      "Epoch 89/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0106 - accuracy: 0.9964 - precision: 0.9933 - recall: 0.9923 - f1: 0.9927 - val_loss: 0.0772 - val_accuracy: 0.9820 - val_precision: 0.9569 - val_recall: 0.9558 - val_f1: 0.9559\n",
      "Epoch 90/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0088 - accuracy: 0.9974 - precision: 0.9963 - recall: 0.9938 - f1: 0.9950 - val_loss: 0.0733 - val_accuracy: 0.9797 - val_precision: 0.9530 - val_recall: 0.9474 - val_f1: 0.9500\n",
      "Epoch 91/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0093 - accuracy: 0.9975 - precision: 0.9953 - recall: 0.9946 - f1: 0.9949 - val_loss: 0.0785 - val_accuracy: 0.9807 - val_precision: 0.9455 - val_recall: 0.9592 - val_f1: 0.9521\n",
      "Epoch 92/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0090 - accuracy: 0.9972 - precision: 0.9962 - recall: 0.9929 - f1: 0.9945 - val_loss: 0.0908 - val_accuracy: 0.9765 - val_precision: 0.9265 - val_recall: 0.9649 - val_f1: 0.9450\n",
      "Epoch 93/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0102 - accuracy: 0.9971 - precision: 0.9948 - recall: 0.9942 - f1: 0.9944 - val_loss: 0.0931 - val_accuracy: 0.9755 - val_precision: 0.9602 - val_recall: 0.9294 - val_f1: 0.9441\n",
      "Epoch 94/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0091 - accuracy: 0.9970 - precision: 0.9965 - recall: 0.9918 - f1: 0.9941 - val_loss: 0.0815 - val_accuracy: 0.9804 - val_precision: 0.9725 - val_recall: 0.9420 - val_f1: 0.9561\n",
      "Epoch 95/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0089 - accuracy: 0.9970 - precision: 0.9945 - recall: 0.9934 - f1: 0.9939 - val_loss: 0.0828 - val_accuracy: 0.9791 - val_precision: 0.9726 - val_recall: 0.9378 - val_f1: 0.9540\n",
      "Epoch 96/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0088 - accuracy: 0.9968 - precision: 0.9952 - recall: 0.9918 - f1: 0.9934 - val_loss: 0.0917 - val_accuracy: 0.9772 - val_precision: 0.9284 - val_recall: 0.9643 - val_f1: 0.9456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0087 - accuracy: 0.9971 - precision: 0.9946 - recall: 0.9939 - f1: 0.9942 - val_loss: 0.0835 - val_accuracy: 0.9817 - val_precision: 0.9729 - val_recall: 0.9478 - val_f1: 0.9593\n",
      "Epoch 98/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0062 - accuracy: 0.9982 - precision: 0.9975 - recall: 0.9953 - f1: 0.9964 - val_loss: 0.0778 - val_accuracy: 0.9813 - val_precision: 0.9630 - val_recall: 0.9480 - val_f1: 0.9550\n",
      "Epoch 99/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0080 - accuracy: 0.9971 - precision: 0.9945 - recall: 0.9943 - f1: 0.9943 - val_loss: 0.1040 - val_accuracy: 0.9772 - val_precision: 0.9826 - val_recall: 0.9201 - val_f1: 0.9497\n",
      "Epoch 100/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0083 - accuracy: 0.9975 - precision: 0.9960 - recall: 0.9939 - f1: 0.9949 - val_loss: 0.0842 - val_accuracy: 0.9817 - val_precision: 0.9699 - val_recall: 0.9496 - val_f1: 0.9587\n",
      "Epoch 101/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0057 - accuracy: 0.9984 - precision: 0.9971 - recall: 0.9966 - f1: 0.9968 - val_loss: 0.0865 - val_accuracy: 0.9810 - val_precision: 0.9651 - val_recall: 0.9536 - val_f1: 0.9584\n",
      "Epoch 102/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0065 - accuracy: 0.9979 - precision: 0.9975 - recall: 0.9945 - f1: 0.9960 - val_loss: 0.0935 - val_accuracy: 0.9791 - val_precision: 0.9408 - val_recall: 0.9582 - val_f1: 0.9492\n",
      "Epoch 103/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0079 - accuracy: 0.9973 - precision: 0.9943 - recall: 0.9950 - f1: 0.9945 - val_loss: 0.0852 - val_accuracy: 0.9784 - val_precision: 0.9622 - val_recall: 0.9389 - val_f1: 0.9501\n",
      "Epoch 104/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0062 - accuracy: 0.9985 - precision: 0.9979 - recall: 0.9960 - f1: 0.9969 - val_loss: 0.0864 - val_accuracy: 0.9817 - val_precision: 0.9624 - val_recall: 0.9580 - val_f1: 0.9590\n",
      "Epoch 105/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0059 - accuracy: 0.9985 - precision: 0.9982 - recall: 0.9959 - f1: 0.9970 - val_loss: 0.0847 - val_accuracy: 0.9807 - val_precision: 0.9428 - val_recall: 0.9611 - val_f1: 0.9517\n",
      "Epoch 106/500\n",
      "110/110 [==============================] - 3s 25ms/step - loss: 0.0054 - accuracy: 0.9983 - precision: 0.9967 - recall: 0.9964 - f1: 0.9965 - val_loss: 0.0858 - val_accuracy: 0.9801 - val_precision: 0.9701 - val_recall: 0.9427 - val_f1: 0.9554\n",
      "Epoch 107/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0089 - accuracy: 0.9964 - precision: 0.9949 - recall: 0.9911 - f1: 0.9929 - val_loss: 0.0830 - val_accuracy: 0.9801 - val_precision: 0.9521 - val_recall: 0.9558 - val_f1: 0.9537\n",
      "Epoch 108/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0049 - accuracy: 0.9983 - precision: 0.9967 - recall: 0.9965 - f1: 0.9966 - val_loss: 0.0890 - val_accuracy: 0.9788 - val_precision: 0.9738 - val_recall: 0.9349 - val_f1: 0.9531\n",
      "Epoch 109/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0049 - accuracy: 0.9987 - precision: 0.9985 - recall: 0.9962 - f1: 0.9973 - val_loss: 0.0879 - val_accuracy: 0.9804 - val_precision: 0.9614 - val_recall: 0.9458 - val_f1: 0.9531\n",
      "Epoch 110/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0061 - accuracy: 0.9983 - precision: 0.9969 - recall: 0.9962 - f1: 0.9965 - val_loss: 0.0903 - val_accuracy: 0.9797 - val_precision: 0.9504 - val_recall: 0.9554 - val_f1: 0.9526\n",
      "Epoch 111/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0058 - accuracy: 0.9979 - precision: 0.9970 - recall: 0.9951 - f1: 0.9960 - val_loss: 0.0893 - val_accuracy: 0.9791 - val_precision: 0.9570 - val_recall: 0.9472 - val_f1: 0.9517\n",
      "Epoch 112/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0074 - accuracy: 0.9979 - precision: 0.9964 - recall: 0.9954 - f1: 0.9958 - val_loss: 0.0886 - val_accuracy: 0.9797 - val_precision: 0.9517 - val_recall: 0.9546 - val_f1: 0.9528\n",
      "Epoch 113/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0051 - accuracy: 0.9986 - precision: 0.9970 - recall: 0.9978 - f1: 0.9974 - val_loss: 0.0908 - val_accuracy: 0.9781 - val_precision: 0.9592 - val_recall: 0.9485 - val_f1: 0.9528\n",
      "Epoch 114/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0054 - accuracy: 0.9983 - precision: 0.9964 - recall: 0.9964 - f1: 0.9964 - val_loss: 0.0949 - val_accuracy: 0.9797 - val_precision: 0.9666 - val_recall: 0.9463 - val_f1: 0.9554\n",
      "Epoch 115/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0056 - accuracy: 0.9985 - precision: 0.9981 - recall: 0.9959 - f1: 0.9970 - val_loss: 0.0980 - val_accuracy: 0.9784 - val_precision: 0.9424 - val_recall: 0.9599 - val_f1: 0.9506\n",
      "Epoch 116/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0060 - accuracy: 0.9980 - precision: 0.9963 - recall: 0.9957 - f1: 0.9960 - val_loss: 0.0871 - val_accuracy: 0.9820 - val_precision: 0.9549 - val_recall: 0.9603 - val_f1: 0.9572\n",
      "Epoch 117/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0053 - accuracy: 0.9984 - precision: 0.9973 - recall: 0.9963 - f1: 0.9968 - val_loss: 0.0969 - val_accuracy: 0.9794 - val_precision: 0.9425 - val_recall: 0.9558 - val_f1: 0.9489\n",
      "Epoch 118/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0040 - accuracy: 0.9986 - precision: 0.9983 - recall: 0.9963 - f1: 0.9973 - val_loss: 0.0918 - val_accuracy: 0.9797 - val_precision: 0.9437 - val_recall: 0.9558 - val_f1: 0.9495\n",
      "Epoch 119/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0037 - accuracy: 0.9990 - precision: 0.9980 - recall: 0.9981 - f1: 0.9980 - val_loss: 0.0922 - val_accuracy: 0.9807 - val_precision: 0.9680 - val_recall: 0.9484 - val_f1: 0.9572\n",
      "Epoch 120/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0051 - accuracy: 0.9982 - precision: 0.9960 - recall: 0.9971 - f1: 0.9965 - val_loss: 0.0881 - val_accuracy: 0.9804 - val_precision: 0.9565 - val_recall: 0.9519 - val_f1: 0.9537\n",
      "Epoch 121/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0053 - accuracy: 0.9982 - precision: 0.9973 - recall: 0.9958 - f1: 0.9965 - val_loss: 0.0910 - val_accuracy: 0.9788 - val_precision: 0.9613 - val_recall: 0.9392 - val_f1: 0.9497\n",
      "Epoch 122/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0051 - accuracy: 0.9983 - precision: 0.9968 - recall: 0.9966 - f1: 0.9967 - val_loss: 0.0922 - val_accuracy: 0.9797 - val_precision: 0.9593 - val_recall: 0.9459 - val_f1: 0.9521\n",
      "Epoch 123/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0046 - accuracy: 0.9988 - precision: 0.9985 - recall: 0.9968 - f1: 0.9976 - val_loss: 0.1057 - val_accuracy: 0.9772 - val_precision: 0.9251 - val_recall: 0.9695 - val_f1: 0.9466\n",
      "Epoch 124/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0078 - accuracy: 0.9972 - precision: 0.9943 - recall: 0.9950 - f1: 0.9946 - val_loss: 0.0884 - val_accuracy: 0.9813 - val_precision: 0.9481 - val_recall: 0.9575 - val_f1: 0.9526\n",
      "Epoch 125/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0050 - accuracy: 0.9983 - precision: 0.9965 - recall: 0.9968 - f1: 0.9966 - val_loss: 0.0915 - val_accuracy: 0.9801 - val_precision: 0.9575 - val_recall: 0.9578 - val_f1: 0.9565\n",
      "Epoch 126/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0034 - accuracy: 0.9990 - precision: 0.9982 - recall: 0.9979 - f1: 0.9980 - val_loss: 0.1006 - val_accuracy: 0.9807 - val_precision: 0.9485 - val_recall: 0.9609 - val_f1: 0.9543\n",
      "Epoch 127/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0039 - accuracy: 0.9988 - precision: 0.9978 - recall: 0.9972 - f1: 0.9975 - val_loss: 0.0928 - val_accuracy: 0.9807 - val_precision: 0.9711 - val_recall: 0.9444 - val_f1: 0.9566\n",
      "Epoch 128/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0048 - accuracy: 0.9987 - precision: 0.9978 - recall: 0.9971 - f1: 0.9974 - val_loss: 0.0978 - val_accuracy: 0.9778 - val_precision: 0.9741 - val_recall: 0.9302 - val_f1: 0.9507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0045 - accuracy: 0.9984 - precision: 0.9983 - recall: 0.9957 - f1: 0.9970 - val_loss: 0.0965 - val_accuracy: 0.9804 - val_precision: 0.9542 - val_recall: 0.9627 - val_f1: 0.9572\n",
      "Epoch 130/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0041 - accuracy: 0.9987 - precision: 0.9972 - recall: 0.9979 - f1: 0.9975 - val_loss: 0.0981 - val_accuracy: 0.9794 - val_precision: 0.9575 - val_recall: 0.9553 - val_f1: 0.9554\n",
      "Epoch 131/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0040 - accuracy: 0.9987 - precision: 0.9980 - recall: 0.9967 - f1: 0.9973 - val_loss: 0.1085 - val_accuracy: 0.9781 - val_precision: 0.9384 - val_recall: 0.9636 - val_f1: 0.9504\n",
      "Epoch 132/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0049 - accuracy: 0.9986 - precision: 0.9965 - recall: 0.9980 - f1: 0.9972 - val_loss: 0.0901 - val_accuracy: 0.9829 - val_precision: 0.9615 - val_recall: 0.9632 - val_f1: 0.9613\n",
      "Epoch 133/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0024 - accuracy: 0.9994 - precision: 0.9986 - recall: 0.9991 - f1: 0.9988 - val_loss: 0.1121 - val_accuracy: 0.9752 - val_precision: 0.9685 - val_recall: 0.9180 - val_f1: 0.9422\n",
      "Epoch 134/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0039 - accuracy: 0.9991 - precision: 0.9991 - recall: 0.9976 - f1: 0.9983 - val_loss: 0.1066 - val_accuracy: 0.9797 - val_precision: 0.9599 - val_recall: 0.9442 - val_f1: 0.9516\n",
      "Epoch 135/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0036 - accuracy: 0.9989 - precision: 0.9978 - recall: 0.9980 - f1: 0.9979 - val_loss: 0.0940 - val_accuracy: 0.9807 - val_precision: 0.9582 - val_recall: 0.9604 - val_f1: 0.9581\n",
      "Epoch 136/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0044 - accuracy: 0.9984 - precision: 0.9976 - recall: 0.9960 - f1: 0.9968 - val_loss: 0.0980 - val_accuracy: 0.9817 - val_precision: 0.9722 - val_recall: 0.9465 - val_f1: 0.9583\n",
      "Epoch 137/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0033 - accuracy: 0.9990 - precision: 0.9982 - recall: 0.9977 - f1: 0.9979 - val_loss: 0.1030 - val_accuracy: 0.9797 - val_precision: 0.9742 - val_recall: 0.9380 - val_f1: 0.9549\n",
      "Epoch 138/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0044 - accuracy: 0.9986 - precision: 0.9977 - recall: 0.9970 - f1: 0.9974 - val_loss: 0.1257 - val_accuracy: 0.9707 - val_precision: 0.9041 - val_recall: 0.9709 - val_f1: 0.9359\n",
      "Epoch 139/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0058 - accuracy: 0.9980 - precision: 0.9962 - recall: 0.9955 - f1: 0.9958 - val_loss: 0.0886 - val_accuracy: 0.9817 - val_precision: 0.9655 - val_recall: 0.9553 - val_f1: 0.9593\n",
      "Epoch 140/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0050 - accuracy: 0.9983 - precision: 0.9968 - recall: 0.9967 - f1: 0.9967 - val_loss: 0.0870 - val_accuracy: 0.9823 - val_precision: 0.9600 - val_recall: 0.9549 - val_f1: 0.9571\n",
      "Epoch 141/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0043 - accuracy: 0.9984 - precision: 0.9974 - recall: 0.9963 - f1: 0.9968 - val_loss: 0.1033 - val_accuracy: 0.9807 - val_precision: 0.9743 - val_recall: 0.9405 - val_f1: 0.9563\n",
      "Epoch 142/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0037 - accuracy: 0.9990 - precision: 0.9981 - recall: 0.9980 - f1: 0.9980 - val_loss: 0.1000 - val_accuracy: 0.9804 - val_precision: 0.9663 - val_recall: 0.9478 - val_f1: 0.9560\n",
      "Epoch 143/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0026 - accuracy: 0.9993 - precision: 0.9985 - recall: 0.9985 - f1: 0.9985 - val_loss: 0.0958 - val_accuracy: 0.9817 - val_precision: 0.9582 - val_recall: 0.9624 - val_f1: 0.9591\n",
      "Epoch 144/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0030 - accuracy: 0.9990 - precision: 0.9984 - recall: 0.9979 - f1: 0.9981 - val_loss: 0.0940 - val_accuracy: 0.9810 - val_precision: 0.9605 - val_recall: 0.9575 - val_f1: 0.9580\n",
      "Epoch 145/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0023 - accuracy: 0.9992 - precision: 0.9984 - recall: 0.9981 - f1: 0.9982 - val_loss: 0.1035 - val_accuracy: 0.9784 - val_precision: 0.9323 - val_recall: 0.9647 - val_f1: 0.9481\n",
      "Epoch 146/500\n",
      "110/110 [==============================] - 3s 25ms/step - loss: 0.0036 - accuracy: 0.9990 - precision: 0.9976 - recall: 0.9984 - f1: 0.9980 - val_loss: 0.0973 - val_accuracy: 0.9804 - val_precision: 0.9717 - val_recall: 0.9437 - val_f1: 0.9566uracy: 0.9990 - precision: 0.9976 - recall: 0.9984 - f1: 0.\n",
      "Epoch 147/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0024 - accuracy: 0.9994 - precision: 0.9990 - recall: 0.9986 - f1: 0.9988 - val_loss: 0.1011 - val_accuracy: 0.9813 - val_precision: 0.9647 - val_recall: 0.9537 - val_f1: 0.9581\n",
      "Epoch 148/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0040 - accuracy: 0.9987 - precision: 0.9974 - recall: 0.9975 - f1: 0.9974 - val_loss: 0.1105 - val_accuracy: 0.9810 - val_precision: 0.9450 - val_recall: 0.9672 - val_f1: 0.9555\n",
      "Epoch 149/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0031 - accuracy: 0.9994 - precision: 0.9992 - recall: 0.9985 - f1: 0.9988 - val_loss: 0.1258 - val_accuracy: 0.9759 - val_precision: 0.9772 - val_recall: 0.9189 - val_f1: 0.9464\n",
      "Epoch 150/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0032 - accuracy: 0.9992 - precision: 0.9991 - recall: 0.9975 - f1: 0.9983 - val_loss: 0.1021 - val_accuracy: 0.9823 - val_precision: 0.9646 - val_recall: 0.9575 - val_f1: 0.9600\n",
      "Epoch 151/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0035 - accuracy: 0.9990 - precision: 0.9986 - recall: 0.9976 - f1: 0.9981 - val_loss: 0.0962 - val_accuracy: 0.9810 - val_precision: 0.9549 - val_recall: 0.9545 - val_f1: 0.9543\n",
      "Epoch 152/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0019 - accuracy: 0.9995 - precision: 0.9997 - recall: 0.9982 - f1: 0.9989 - val_loss: 0.1063 - val_accuracy: 0.9807 - val_precision: 0.9592 - val_recall: 0.9493 - val_f1: 0.9539\n",
      "Epoch 153/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0020 - accuracy: 0.9997 - precision: 0.9995 - recall: 0.9993 - f1: 0.9994 - val_loss: 0.0996 - val_accuracy: 0.9826 - val_precision: 0.9735 - val_recall: 0.9489 - val_f1: 0.9602\n",
      "Epoch 154/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0036 - accuracy: 0.9989 - precision: 0.9978 - recall: 0.9978 - f1: 0.9978 - val_loss: 0.1150 - val_accuracy: 0.9775 - val_precision: 0.9381 - val_recall: 0.9610 - val_f1: 0.9489\n",
      "Epoch 155/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0038 - accuracy: 0.9987 - precision: 0.9971 - recall: 0.9976 - f1: 0.9973 - val_loss: 0.1025 - val_accuracy: 0.9807 - val_precision: 0.9639 - val_recall: 0.9528 - val_f1: 0.9573\n",
      "Epoch 156/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0024 - accuracy: 0.9993 - precision: 0.9989 - recall: 0.9984 - f1: 0.9987 - val_loss: 0.1134 - val_accuracy: 0.9794 - val_precision: 0.9765 - val_recall: 0.9332 - val_f1: 0.9534\n",
      "Epoch 157/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0025 - accuracy: 0.9991 - precision: 0.9990 - recall: 0.9976 - f1: 0.9983 - val_loss: 0.1011 - val_accuracy: 0.9820 - val_precision: 0.9609 - val_recall: 0.9523 - val_f1: 0.9562\n",
      "Epoch 158/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0033 - accuracy: 0.9991 - precision: 0.9985 - recall: 0.9978 - f1: 0.9981 - val_loss: 0.1011 - val_accuracy: 0.9817 - val_precision: 0.9707 - val_recall: 0.9499 - val_f1: 0.9592\n",
      "Epoch 159/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0023 - accuracy: 0.9996 - precision: 0.9993 - recall: 0.9990 - f1: 0.9992 - val_loss: 0.1044 - val_accuracy: 0.9817 - val_precision: 0.9567 - val_recall: 0.9551 - val_f1: 0.9555\n",
      "Epoch 160/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0015 - accuracy: 0.9997 - precision: 0.9993 - recall: 0.9995 - f1: 0.9994 - val_loss: 0.1290 - val_accuracy: 0.9781 - val_precision: 0.9317 - val_recall: 0.9716 - val_f1: 0.9506\n",
      "Epoch 161/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0021 - accuracy: 0.9993 - precision: 0.9986 - recall: 0.9986 - f1: 0.9986 - val_loss: 0.1049 - val_accuracy: 0.9823 - val_precision: 0.9706 - val_recall: 0.9511 - val_f1: 0.9597\n",
      "Epoch 162/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0019 - accuracy: 0.9994 - precision: 0.9992 - recall: 0.9987 - f1: 0.9989 - val_loss: 0.1079 - val_accuracy: 0.9791 - val_precision: 0.9678 - val_recall: 0.9420 - val_f1: 0.9538\n",
      "Epoch 163/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0024 - accuracy: 0.9989 - precision: 0.9983 - recall: 0.9972 - f1: 0.9978 - val_loss: 0.1071 - val_accuracy: 0.9801 - val_precision: 0.9646 - val_recall: 0.9493 - val_f1: 0.9559\n",
      "Epoch 164/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0015 - accuracy: 0.9997 - precision: 0.9995 - recall: 0.9993 - f1: 0.9994 - val_loss: 0.1071 - val_accuracy: 0.9801 - val_precision: 0.9501 - val_recall: 0.9576 - val_f1: 0.9534\n",
      "Epoch 165/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0024 - accuracy: 0.9992 - precision: 0.9977 - recall: 0.9991 - f1: 0.9984 - val_loss: 0.1120 - val_accuracy: 0.9801 - val_precision: 0.9597 - val_recall: 0.9466 - val_f1: 0.9527\n",
      "Epoch 166/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0030 - accuracy: 0.9990 - precision: 0.9985 - recall: 0.9971 - f1: 0.9978 - val_loss: 0.1054 - val_accuracy: 0.9813 - val_precision: 0.9682 - val_recall: 0.9506 - val_f1: 0.9583\n",
      "Epoch 167/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0025 - accuracy: 0.9992 - precision: 0.9990 - recall: 0.9980 - f1: 0.9985 - val_loss: 0.1078 - val_accuracy: 0.9810 - val_precision: 0.9690 - val_recall: 0.9484 - val_f1: 0.9577\n",
      "Epoch 168/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0014 - accuracy: 0.9997 - precision: 0.9996 - recall: 0.9991 - f1: 0.9993 - val_loss: 0.1084 - val_accuracy: 0.9804 - val_precision: 0.9515 - val_recall: 0.9561 - val_f1: 0.9534\n",
      "Epoch 169/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0017 - accuracy: 0.9995 - precision: 0.9988 - recall: 0.9993 - f1: 0.9990 - val_loss: 0.1106 - val_accuracy: 0.9775 - val_precision: 0.9589 - val_recall: 0.9463 - val_f1: 0.9516\n",
      "Epoch 170/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0036 - accuracy: 0.9988 - precision: 0.9982 - recall: 0.9972 - f1: 0.9977 - val_loss: 0.1212 - val_accuracy: 0.9778 - val_precision: 0.9356 - val_recall: 0.9589 - val_f1: 0.9468\n",
      "Epoch 171/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0037 - accuracy: 0.9989 - precision: 0.9975 - recall: 0.9982 - f1: 0.9978 - val_loss: 0.1062 - val_accuracy: 0.9810 - val_precision: 0.9732 - val_recall: 0.9448 - val_f1: 0.9578\n",
      "Epoch 172/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0037 - accuracy: 0.9984 - precision: 0.9980 - recall: 0.9957 - f1: 0.9968 - val_loss: 0.1079 - val_accuracy: 0.9813 - val_precision: 0.9683 - val_recall: 0.9506 - val_f1: 0.9585\n",
      "Epoch 173/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0022 - accuracy: 0.9995 - precision: 0.9988 - recall: 0.9994 - f1: 0.9991 - val_loss: 0.1110 - val_accuracy: 0.9817 - val_precision: 0.9682 - val_recall: 0.9520 - val_f1: 0.9591\n",
      "Epoch 174/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0033 - accuracy: 0.9989 - precision: 0.9980 - recall: 0.9977 - f1: 0.9978 - val_loss: 0.1066 - val_accuracy: 0.9817 - val_precision: 0.9714 - val_recall: 0.9477 - val_f1: 0.9585\n",
      "Epoch 175/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0025 - accuracy: 0.9990 - precision: 0.9982 - recall: 0.9980 - f1: 0.9981 - val_loss: 0.1143 - val_accuracy: 0.9791 - val_precision: 0.9746 - val_recall: 0.9349 - val_f1: 0.9534\n",
      "Epoch 176/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0026 - accuracy: 0.9991 - precision: 0.9980 - recall: 0.9984 - f1: 0.9982 - val_loss: 0.1224 - val_accuracy: 0.9797 - val_precision: 0.9719 - val_recall: 0.9392 - val_f1: 0.9543\n",
      "Epoch 177/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0034 - accuracy: 0.9988 - precision: 0.9984 - recall: 0.9967 - f1: 0.9976 - val_loss: 0.1315 - val_accuracy: 0.9778 - val_precision: 0.9462 - val_recall: 0.9613 - val_f1: 0.9524\n",
      "Epoch 178/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0021 - accuracy: 0.9991 - precision: 0.9981 - recall: 0.9983 - f1: 0.9982 - val_loss: 0.1199 - val_accuracy: 0.9794 - val_precision: 0.9525 - val_recall: 0.9514 - val_f1: 0.9516\n",
      "Epoch 179/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0015 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9990 - f1: 0.9993 - val_loss: 0.1269 - val_accuracy: 0.9775 - val_precision: 0.9728 - val_recall: 0.9305 - val_f1: 0.9503\n",
      "Epoch 180/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0027 - accuracy: 0.9991 - precision: 0.9987 - recall: 0.9979 - f1: 0.9982 - val_loss: 0.1070 - val_accuracy: 0.9820 - val_precision: 0.9704 - val_recall: 0.9507 - val_f1: 0.9595\n",
      "Epoch 181/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0037 - accuracy: 0.9988 - precision: 0.9984 - recall: 0.9970 - f1: 0.9977 - val_loss: 0.1174 - val_accuracy: 0.9788 - val_precision: 0.9576 - val_recall: 0.9434 - val_f1: 0.9501\n",
      "Epoch 182/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0039 - accuracy: 0.9987 - precision: 0.9981 - recall: 0.9966 - f1: 0.9973 - val_loss: 0.1267 - val_accuracy: 0.9801 - val_precision: 0.9742 - val_recall: 0.9387 - val_f1: 0.9552\n",
      "Epoch 183/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0031 - accuracy: 0.9988 - precision: 0.9980 - recall: 0.9971 - f1: 0.9975 - val_loss: 0.1126 - val_accuracy: 0.9813 - val_precision: 0.9633 - val_recall: 0.9547 - val_f1: 0.9579\n",
      "Epoch 184/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0015 - accuracy: 0.9994 - precision: 0.9983 - recall: 0.9994 - f1: 0.9989 - val_loss: 0.1108 - val_accuracy: 0.9810 - val_precision: 0.9583 - val_recall: 0.9594 - val_f1: 0.9577\n",
      "Epoch 185/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 8.3028e-04 - accuracy: 0.9999 - precision: 0.9996 - recall: 1.0000 - f1: 0.9998 - val_loss: 0.1254 - val_accuracy: 0.9778 - val_precision: 0.9377 - val_recall: 0.9619 - val_f1: 0.9492\n",
      "Epoch 186/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0016 - accuracy: 0.9996 - precision: 0.9993 - recall: 0.9990 - f1: 0.9991 - val_loss: 0.1269 - val_accuracy: 0.9794 - val_precision: 0.9492 - val_recall: 0.9565 - val_f1: 0.9524\n",
      "Epoch 187/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0031 - accuracy: 0.9993 - precision: 0.9988 - recall: 0.9983 - f1: 0.9985 - val_loss: 0.1136 - val_accuracy: 0.9807 - val_precision: 0.9549 - val_recall: 0.9537 - val_f1: 0.9540\n",
      "Epoch 188/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0024 - accuracy: 0.9993 - precision: 0.9990 - recall: 0.9982 - f1: 0.9986 - val_loss: 0.1235 - val_accuracy: 0.9817 - val_precision: 0.9612 - val_recall: 0.9500 - val_f1: 0.9552\n",
      "Epoch 189/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0052 - accuracy: 0.9982 - precision: 0.9972 - recall: 0.9953 - f1: 0.9962 - val_loss: 0.1181 - val_accuracy: 0.9772 - val_precision: 0.9426 - val_recall: 0.9540 - val_f1: 0.9479\n",
      "Epoch 190/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0011 - accuracy: 0.9998 - precision: 0.9999 - recall: 0.9995 - f1: 0.9997 - val_loss: 0.1149 - val_accuracy: 0.9794 - val_precision: 0.9536 - val_recall: 0.9505 - val_f1: 0.9516\n",
      "Epoch 191/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0013 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9987 - f1: 0.9992 - val_loss: 0.1143 - val_accuracy: 0.9784 - val_precision: 0.9412 - val_recall: 0.9534 - val_f1: 0.9471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0019 - accuracy: 0.9995 - precision: 0.9992 - recall: 0.9990 - f1: 0.9991 - val_loss: 0.1229 - val_accuracy: 0.9807 - val_precision: 0.9697 - val_recall: 0.9452 - val_f1: 0.9564\n",
      "Epoch 193/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0019 - accuracy: 0.9993 - precision: 0.9991 - recall: 0.9983 - f1: 0.9987 - val_loss: 0.1205 - val_accuracy: 0.9794 - val_precision: 0.9673 - val_recall: 0.9362 - val_f1: 0.9511\n",
      "Epoch 194/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0016 - accuracy: 0.9997 - precision: 0.9992 - recall: 0.9996 - f1: 0.9994 - val_loss: 0.1175 - val_accuracy: 0.9801 - val_precision: 0.9621 - val_recall: 0.9515 - val_f1: 0.9558\n",
      "Epoch 195/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0012 - accuracy: 0.9996 - precision: 0.9994 - recall: 0.9988 - f1: 0.9991 - val_loss: 0.1191 - val_accuracy: 0.9791 - val_precision: 0.9407 - val_recall: 0.9573 - val_f1: 0.9487\n",
      "Epoch 196/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0018 - accuracy: 0.9992 - precision: 0.9989 - recall: 0.9980 - f1: 0.9985 - val_loss: 0.1231 - val_accuracy: 0.9794 - val_precision: 0.9465 - val_recall: 0.9587 - val_f1: 0.9522\n",
      "Epoch 197/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0017 - accuracy: 0.9995 - precision: 0.9992 - recall: 0.9989 - f1: 0.9990 - val_loss: 0.1088 - val_accuracy: 0.9772 - val_precision: 0.9598 - val_recall: 0.9433 - val_f1: 0.9506\n",
      "Epoch 198/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0027 - accuracy: 0.9992 - precision: 0.9986 - recall: 0.9982 - f1: 0.9984 - val_loss: 0.1292 - val_accuracy: 0.9784 - val_precision: 0.9573 - val_recall: 0.9515 - val_f1: 0.9532\n",
      "Epoch 199/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0032 - accuracy: 0.9990 - precision: 0.9986 - recall: 0.9979 - f1: 0.9982 - val_loss: 0.1106 - val_accuracy: 0.9826 - val_precision: 0.9608 - val_recall: 0.9633 - val_f1: 0.9609\n",
      "Epoch 200/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0032 - accuracy: 0.9991 - precision: 0.9980 - recall: 0.9982 - f1: 0.9981 - val_loss: 0.1164 - val_accuracy: 0.9813 - val_precision: 0.9554 - val_recall: 0.9643 - val_f1: 0.9587\n",
      "Epoch 201/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0022 - accuracy: 0.9995 - precision: 0.9986 - recall: 0.9992 - f1: 0.9989 - val_loss: 0.1183 - val_accuracy: 0.9807 - val_precision: 0.9567 - val_recall: 0.9515 - val_f1: 0.9537\n",
      "Epoch 202/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 5.3449e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9810 - val_precision: 0.9572 - val_recall: 0.9527 - val_f1: 0.9546\n",
      "Epoch 203/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0011 - accuracy: 0.9997 - precision: 0.9997 - recall: 0.9993 - f1: 0.9995 - val_loss: 0.1219 - val_accuracy: 0.9807 - val_precision: 0.9466 - val_recall: 0.9632 - val_f1: 0.9543\n",
      "Epoch 204/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0022 - accuracy: 0.9993 - precision: 0.9989 - recall: 0.9983 - f1: 0.9986 - val_loss: 0.1213 - val_accuracy: 0.9784 - val_precision: 0.9428 - val_recall: 0.9580 - val_f1: 0.9499\n",
      "Epoch 205/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0019 - accuracy: 0.9994 - precision: 0.9991 - recall: 0.9985 - f1: 0.9988 - val_loss: 0.1272 - val_accuracy: 0.9788 - val_precision: 0.9580 - val_recall: 0.9433 - val_f1: 0.9502\n",
      "Epoch 206/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0029 - accuracy: 0.9987 - precision: 0.9981 - recall: 0.9968 - f1: 0.9974 - val_loss: 0.1123 - val_accuracy: 0.9820 - val_precision: 0.9562 - val_recall: 0.9575 - val_f1: 0.9565\n",
      "Epoch 207/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0027 - accuracy: 0.9989 - precision: 0.9974 - recall: 0.9982 - f1: 0.9978 - val_loss: 0.1172 - val_accuracy: 0.9801 - val_precision: 0.9705 - val_recall: 0.9433 - val_f1: 0.9557\n",
      "Epoch 208/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 8.5263e-04 - accuracy: 0.9998 - precision: 1.0000 - recall: 0.9994 - f1: 0.9997 - val_loss: 0.1188 - val_accuracy: 0.9794 - val_precision: 0.9693 - val_recall: 0.9422 - val_f1: 0.9546\n",
      "Epoch 209/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0024 - accuracy: 0.9992 - precision: 0.9982 - recall: 0.9985 - f1: 0.9984 - val_loss: 0.1168 - val_accuracy: 0.9807 - val_precision: 0.9548 - val_recall: 0.9634 - val_f1: 0.9579\n",
      "Epoch 210/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0027 - accuracy: 0.9993 - precision: 0.9986 - recall: 0.9986 - f1: 0.9986 - val_loss: 0.1213 - val_accuracy: 0.9788 - val_precision: 0.9607 - val_recall: 0.9498 - val_f1: 0.9542\n",
      "Epoch 211/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0018 - accuracy: 0.9993 - precision: 0.9986 - recall: 0.9986 - f1: 0.9986 - val_loss: 0.1139 - val_accuracy: 0.9794 - val_precision: 0.9476 - val_recall: 0.9575 - val_f1: 0.9521\n",
      "Epoch 212/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0015 - accuracy: 0.9996 - precision: 0.9994 - recall: 0.9988 - f1: 0.9991 - val_loss: 0.1127 - val_accuracy: 0.9804 - val_precision: 0.9607 - val_recall: 0.9550 - val_f1: 0.9567\n",
      "Epoch 213/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0016 - accuracy: 0.9995 - precision: 0.9994 - recall: 0.9985 - f1: 0.9990 - val_loss: 0.1168 - val_accuracy: 0.9801 - val_precision: 0.9503 - val_recall: 0.9581 - val_f1: 0.9537\n",
      "Epoch 214/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0011 - accuracy: 0.9996 - precision: 0.9992 - recall: 0.9992 - f1: 0.9992 - val_loss: 0.1207 - val_accuracy: 0.9797 - val_precision: 0.9589 - val_recall: 0.9454 - val_f1: 0.9517\n",
      "Epoch 215/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0018 - accuracy: 0.9996 - precision: 0.9992 - recall: 0.9992 - f1: 0.9992 - val_loss: 0.1203 - val_accuracy: 0.9797 - val_precision: 0.9680 - val_recall: 0.9452 - val_f1: 0.9555\n",
      "Epoch 216/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0019 - accuracy: 0.9992 - precision: 0.9991 - recall: 0.9977 - f1: 0.9984 - val_loss: 0.1293 - val_accuracy: 0.9794 - val_precision: 0.9549 - val_recall: 0.9575 - val_f1: 0.9551\n",
      "Epoch 217/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0030 - accuracy: 0.9988 - precision: 0.9969 - recall: 0.9982 - f1: 0.9975 - val_loss: 0.1287 - val_accuracy: 0.9801 - val_precision: 0.9666 - val_recall: 0.9469 - val_f1: 0.9557\n",
      "Epoch 218/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 7.6142e-04 - accuracy: 0.9999 - precision: 1.0000 - recall: 0.9996 - f1: 0.9998 - val_loss: 0.1326 - val_accuracy: 0.9804 - val_precision: 0.9590 - val_recall: 0.9481 - val_f1: 0.9531\n",
      "Epoch 219/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0015 - accuracy: 0.9996 - precision: 0.9994 - recall: 0.9990 - f1: 0.9992 - val_loss: 0.1228 - val_accuracy: 0.9807 - val_precision: 0.9480 - val_recall: 0.9556 - val_f1: 0.9516\n",
      "Epoch 220/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0020 - accuracy: 0.9993 - precision: 0.9985 - recall: 0.9987 - f1: 0.9985 - val_loss: 0.1341 - val_accuracy: 0.9791 - val_precision: 0.9590 - val_recall: 0.9522 - val_f1: 0.9545\n",
      "Epoch 221/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 8.0072e-04 - accuracy: 0.9999 - precision: 0.9995 - recall: 0.9999 - f1: 0.9997 - val_loss: 0.1254 - val_accuracy: 0.9813 - val_precision: 0.9490 - val_recall: 0.9629 - val_f1: 0.9555\n",
      "Epoch 222/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0016 - accuracy: 0.9996 - precision: 0.9996 - recall: 0.9989 - f1: 0.9992 - val_loss: 0.1313 - val_accuracy: 0.9826 - val_precision: 0.9627 - val_recall: 0.9610 - val_f1: 0.9608\n",
      "Epoch 223/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0025 - accuracy: 0.9990 - precision: 0.9977 - recall: 0.9982 - f1: 0.9980 - val_loss: 0.1252 - val_accuracy: 0.9801 - val_precision: 0.9691 - val_recall: 0.9455 - val_f1: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0023 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9978 - f1: 0.9986 - val_loss: 0.1288 - val_accuracy: 0.9801 - val_precision: 0.9485 - val_recall: 0.9584 - val_f1: 0.9531\n",
      "Epoch 225/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0031 - accuracy: 0.9990 - precision: 0.9982 - recall: 0.9979 - f1: 0.9980 - val_loss: 0.1285 - val_accuracy: 0.9801 - val_precision: 0.9749 - val_recall: 0.9395 - val_f1: 0.9561\n",
      "Epoch 226/500\n",
      "110/110 [==============================] - 3s 25ms/step - loss: 0.0021 - accuracy: 0.9993 - precision: 0.9989 - recall: 0.9983 - f1: 0.9986 - val_loss: 0.1199 - val_accuracy: 0.9807 - val_precision: 0.9585 - val_recall: 0.9588 - val_f1: 0.9575\n",
      "Epoch 227/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0024 - accuracy: 0.9994 - precision: 0.9984 - recall: 0.9994 - f1: 0.9989 - val_loss: 0.1359 - val_accuracy: 0.9781 - val_precision: 0.9714 - val_recall: 0.9331 - val_f1: 0.9511\n",
      "Epoch 228/500\n",
      "110/110 [==============================] - 3s 24ms/step - loss: 0.0021 - accuracy: 0.9992 - precision: 0.9987 - recall: 0.9982 - f1: 0.9984 - val_loss: 0.1199 - val_accuracy: 0.9813 - val_precision: 0.9576 - val_recall: 0.9523 - val_f1: 0.9545\n",
      "Epoch 229/500\n",
      "110/110 [==============================] - 3s 23ms/step - loss: 0.0015 - accuracy: 0.9996 - precision: 0.9993 - recall: 0.9992 - f1: 0.9993 - val_loss: 0.1192 - val_accuracy: 0.9797 - val_precision: 0.9577 - val_recall: 0.9468 - val_f1: 0.9518\n",
      "Epoch 230/500\n",
      " 67/110 [=================>............] - ETA: 0s - loss: 4.1712e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - f1: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fc0747e46ffc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                              monitor='val_f1', save_best_only=True, mode='max')\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#model.load_weights('model-38-0.93.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hist = model.fit(Xtrain, Ytrain, validation_data=(Xval, Yval), epochs=50)\n",
    "#print(hist.history)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model-{epoch:02d}-{val_f1:.2f}.hdf5\", \n",
    "                             monitor='val_f1', save_best_only=True, mode='max')\n",
    "#model.load_weights('model-38-0.93.hdf5')\n",
    "history_trainable = model.fit(x_train, y_train, batch_size=256, epochs=500, validation_split=0.1, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d05c0fd",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "model.load_weights('model-97-0.96.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78425ac8",
   "metadata": {
    "gradient": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "                               filename\n",
      "0  68f33844-472b-4111-b600-f90d544833c7\n",
      "1  7d93a21d-1f16-49ce-8fcc-edf12c40f549\n",
      "2  4a820650-7acd-489a-ad14-9d7ad8c73b6b\n",
      "3  819b216b-2b6c-4539-a722-70648c0706c6\n",
      "4  45f7c47d-03cc-40cd-acc5-b8c1c57872fa\n",
      "(7, 3)\n",
      "     sign                              filename  sign_predict\n",
      "504     1  8184f255-2bf3-4d16-9cf5-e5296df8db9f      0.956268\n",
      "613     1  0c2eb4b7-a85a-4807-a4e4-4491748a390d      0.959364\n",
      "318     1  8f41c7a6-107f-4200-ba12-70d295e159da      0.973122\n",
      "898     1  4045321a-07c7-4320-abe7-aeebc78c994e      0.978025\n",
      "300     1  f7c60b5d-6385-44cd-a89b-b8677d6b0ff6      0.982522\n",
      "919     1  f4c0f480-725d-4002-961c-703586636e55      0.983860\n",
      "678     1  0664e6a4-610a-4c97-b5e2-b05177de7163      0.986408\n",
      "(17, 3)\n",
      "     sign                              filename  sign_predict\n",
      "407     0  7eb31f80-74c0-43e4-b6c4-bc2ca73afa0d      0.010154\n",
      "703     0  740bd4ef-2ddc-49ae-8622-32bcfc8279c5      0.010347\n",
      "559     0  836f07c6-2f71-43e4-8e16-c14c943015bf      0.010420\n",
      "182     0  6794eedc-8ced-454f-ae8b-7f49f73142c7      0.011164\n",
      "990     0  292c6333-9b68-4320-ae43-bf8022c4e609      0.012299\n",
      "428     0  259840c4-a00f-46dd-badc-b951cb737390      0.015501\n",
      "869     0  4da0d7fb-7cea-4095-aafd-a892acc779c2      0.016897\n",
      "967     0  787a684c-1156-43d0-8169-d7bdcbd3130c      0.019127\n",
      "201     0  facc1bd6-2f63-4d0a-9ed4-bd87bfd848ad      0.019221\n",
      "446     0  f5616895-281b-43b5-99d3-461a3e24ec2e      0.022728\n",
      "848     0  a4dd97be-2faa-4fb1-a4f8-7ad61b5b0f63      0.031068\n",
      "692     0  dd927515-fbc4-4674-b2ef-8ab4601ff049      0.031562\n",
      "639     0  72ac3409-d6f0-4a16-8d54-30ce63567271      0.032209\n",
      "35      0  1aabd008-e397-443a-8aeb-7666cb219958      0.033629\n",
      "568     0  eaffc2bb-1776-4d4a-ad02-89a1f0fe461f      0.039023\n",
      "881     0  be69d3e5-8a4a-4df8-8abf-fcb47a2fa053      0.041592\n",
      "279     0  06747770-8a03-404d-a3c5-71611ffbff0b      0.049027\n"
     ]
    }
   ],
   "source": [
    "result = model.predict_classes(x_test)\n",
    "result_predict = model.predict(x_test)\n",
    "\n",
    "#print(result_predict)\n",
    "\n",
    "print(result.shape)\n",
    "data_test = pd.read_csv('test.csv')\n",
    "print(data_test.head(5))\n",
    "data_test['sign'] = result\n",
    "data_test['sign_predict'] = result_predict\n",
    "data_test = data_test[['sign', 'filename', 'sign_predict']]\n",
    "\n",
    "data_lost = data_test[data_test['sign_predict']<0.99]\n",
    "data_lost = data_lost[data_lost['sign_predict']>=0.95]\n",
    "data_lost = data_lost.sort_values(by='sign_predict')\n",
    "print(data_lost.shape)\n",
    "print(data_lost)\n",
    "\n",
    "data_lost = data_test[data_test['sign_predict']<=0.05]\n",
    "data_lost = data_lost[data_lost['sign_predict']>0.01]\n",
    "data_lost = data_lost.sort_values(by='sign_predict')\n",
    "print(data_lost.shape)\n",
    "print(data_lost)\n",
    "\n",
    "#print(data_test.head(5))\n",
    "#data_true = data_test[data_test['sign']==1]\n",
    "#print(data_true.shape)\n",
    "\n",
    "#перезапись sign\"\"\"\n",
    "\"\"\"\n",
    "index_large = data_test['sign_predict'].nlargest(200).index\n",
    "index_small = data_test['sign_predict'].nsmallest(800).index\n",
    "data_test['sign'].loc[index_large] = 1\n",
    "data_test['sign'].loc[index_small] = 0\n",
    "data_test = data_test[['sign', 'filename']]\n",
    "\n",
    "data_true = data_test[data_test['sign']==1]\n",
    "print(data_true.shape)\"\"\"\n",
    "\n",
    "data_test = data_test[['sign', 'filename']]\n",
    "data_test.to_csv('result_4.csv', index = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1750e8",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "#Посмотреть что не так с 6%\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "r = model.predict_classes(x_train)\n",
    "print(r.shape)\n",
    "data_train = pd.read_csv('train.csv')\n",
    "data_train = pd.concat((data_train, data_train, data_train))\n",
    "print(data_train.head(5))\n",
    "data_train['sign_predict'] = r\n",
    "data_train = data_train[['sign', 'sign_predict', 'filename']]\n",
    "print(data_train.head(5))\n",
    "\n",
    "data_error = data_train[data_train['sign']!=data_train['sign_predict']]\n",
    "print(data_error.shape)\n",
    "curr_path = os.getcwd()\n",
    "directory = os.path.join(curr_path, \"avia-train30_alignment/avia-train\")\n",
    "    \n",
    "for row in data_error.values:\n",
    "    abspath = os.path.join(directory, row[2]+ '.png')\n",
    "    img = cv2.imread(abspath, 0)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    print(f'sign: {row[0]} predict: {row[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab10da8",
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
